2026-02-04 00:58:04.484050: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4
2026-02-04 00:58:04.484096: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB
2026-02-04 00:58:04.484105: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB
2026-02-04 00:58:04.484419: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2026-02-04 00:58:04.484704: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)
vocab_size: 3138 max_word_index: 3128
max_seq_len:  256  word_seq_len:  51
Number of devices: 1
x:  Tensor("Embedding-Token/embedding_lookup/Identity_1:0", shape=(None, None, 128), dtype=float32)
s:  Tensor("Embedding-Segment/embedding_lookup/Identity_1:0", shape=(None, None, 128), dtype=float32)
Q:  Tensor("Embedding-Mapping/BiasAdd:0", shape=(None, None, 256), dtype=float32) 8 32
QW:  Tensor("Transformer-MultiHeadSelfAttention/dense/BiasAdd:0", shape=(None, None, 256), dtype=float32) 8 32
Q:  Tensor("Transformer-FeedForward-Norm/add_1:0", shape=(None, None, 256), dtype=float32) 8 32
QW:  Tensor("Transformer-MultiHeadSelfAttention_1/dense/BiasAdd:0", shape=(None, None, 256), dtype=float32) 8 32
max_position_embeddings: 512
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 Input-Token (InputLayer)    [(None, None)]               0         []                            
                                                                                                  
 Input-Segment (InputLayer)  [(None, None)]               0         []                            
                                                                                                  
 Embedding-Token (Embedding  (None, None, 128)            401664    ['Input-Token[0][0]']         
 )                                                                                                
                                                                                                  
 Embedding-Segment (Embeddi  (None, None, 128)            256       ['Input-Segment[0][0]']       
 ng)                                                                                              
                                                                                                  
 Embedding-Token-Segment (A  (None, None, 128)            0         ['Embedding-Token[0][0]',     
 dd)                                                                 'Embedding-Segment[0][0]']   
                                                                                                  
 Embedding-Position (Positi  (None, None, 128)            65536     ['Embedding-Token-Segment[0][0
 onEmbedding)                                                       ]']                           
                                                                                                  
 Embedding-Norm (LayerNorma  (None, None, 128)            256       ['Embedding-Position[0][0]']  
 lization)                                                                                        
                                                                                                  
 Embedding-Mapping (Dense)   (None, None, 256)            33024     ['Embedding-Norm[0][0]']      
                                                                                                  
 Transformer-MultiHeadSelfA  (None, None, 256)            263168    ['Embedding-Mapping[0][0]',   
 ttention (MultiHeadAttenti                                          'Embedding-Mapping[0][0]',   
 on)                                                                 'Embedding-Mapping[0][0]',   
                                                                     'Transformer-FeedForward-Norm
                                                                    [0][0]',                      
                                                                     'Transformer-FeedForward-Norm
                                                                    [0][0]',                      
                                                                     'Transformer-FeedForward-Norm
                                                                    [0][0]']                      
                                                                                                  
 Transformer-MultiHeadSelfA  (None, None, 256)            0         ['Embedding-Mapping[0][0]',   
 ttention-Add (Add)                                                  'Transformer-MultiHeadSelfAtt
                                                                    ention[0][0]',                
                                                                     'Transformer-FeedForward-Norm
                                                                    [0][0]',                      
                                                                     'Transformer-MultiHeadSelfAtt
                                                                    ention[1][0]']                
                                                                                                  
 Transformer-MultiHeadSelfA  (None, None, 256)            512       ['Transformer-MultiHeadSelfAtt
 ttention-Norm (LayerNormal                                         ention-Add[0][0]',            
 ization)                                                            'Transformer-MultiHeadSelfAtt
                                                                    ention-Add[1][0]']            
                                                                                                  
 Transformer-FeedForward (F  (None, None, 256)            525568    ['Transformer-MultiHeadSelfAtt
 eedForward)                                                        ention-Norm[0][0]',           
                                                                     'Transformer-MultiHeadSelfAtt
                                                                    ention-Norm[1][0]']           
                                                                                                  
 Transformer-FeedForward-Ad  (None, None, 256)            0         ['Transformer-MultiHeadSelfAtt
 d (Add)                                                            ention-Norm[0][0]',           
                                                                     'Transformer-FeedForward[0][0
                                                                    ]',                           
                                                                     'Transformer-MultiHeadSelfAtt
                                                                    ention-Norm[1][0]',           
                                                                     'Transformer-FeedForward[1][0
                                                                    ]']                           
                                                                                                  
 Transformer-FeedForward-No  (None, None, 256)            512       ['Transformer-FeedForward-Add[
 rm (LayerNormalization)                                            0][0]',                       
                                                                     'Transformer-FeedForward-Add[
                                                                    1][0]']                       
                                                                                                  
 CLS-token (Lambda)          (None, 256)                  0         ['Transformer-FeedForward-Norm
                                                                    [1][0]']                      
                                                                                                  
 CLS-Activation (Dense)      (None, 51)                   13107     ['CLS-token[0][0]']           
                                                                                                  
==================================================================================================
Total params: 1303603 (4.97 MB)
Trainable params: 1303603 (4.97 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
/opt/anaconda3/envs/logo-lite/lib/python3.8/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.
  warnings.warn(
WARNING:tensorflow:From /opt/anaconda3/envs/logo-lite/lib/python3.8/site-packages/keras/src/backend.py:7357: StrategyBase.configure (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
use `update_config_proto` instead.
2026-02-04 00:58:04.592337: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2026-02-04 00:58:04.592349: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)
2026-02-04 00:58:04.627699: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled
2026-02-04 00:58:04.631812: W tensorflow/core/common_runtime/colocation_graph.cc:1213] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ReadVariableOp: GPU CPU 
VarHandleOp: GPU CPU 
Mul: GPU CPU 
AssignVariableOp: GPU CPU 
StatelessRandomGetKeyCounter: CPU 
AddV2: GPU CPU 
VarIsInitializedOp: GPU CPU 
StatelessTruncatedNormalV2: GPU CPU 
Const: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  Embedding-Token/embeddings/Initializer/stateless_truncated_normal/shape (Const) 
  Embedding-Token/embeddings/Initializer/stateless_truncated_normal/mean (Const) 
  Embedding-Token/embeddings/Initializer/stateless_truncated_normal/stddev (Const) 
  Embedding-Token/embeddings/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter/seed (Const) 
  Embedding-Token/embeddings/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter (StatelessRandomGetKeyCounter) 
  Embedding-Token/embeddings/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2/alg (Const) 
  Embedding-Token/embeddings/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2 (StatelessTruncatedNormalV2) 
  Embedding-Token/embeddings/Initializer/stateless_truncated_normal/mul (Mul) 
  Embedding-Token/embeddings/Initializer/stateless_truncated_normal (AddV2) 
  Embedding-Token/embeddings (VarHandleOp) /replica:0/task:0/device:GPU:0
  Embedding-Token/embeddings/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /replica:0/task:0/device:GPU:0
  Embedding-Token/embeddings/Assign (AssignVariableOp) /replica:0/task:0/device:GPU:0
  Embedding-Token/embeddings/Read/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  Embedding-Token/embedding_lookup/Identity/ReadVariableOp (ReadVariableOp) 
  Identity/ReadVariableOp (ReadVariableOp) 
  update_0/AssignVariableOp (AssignVariableOp) /replica:0/task:0/device:GPU:0
  update_0/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  VarIsInitializedOp_26 (VarIsInitializedOp) 
  VarIsInitializedOp_27 (VarIsInitializedOp) 

2026-02-04 00:58:04.631854: W tensorflow/core/common_runtime/colocation_graph.cc:1213] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ReadVariableOp: GPU CPU 
VarHandleOp: GPU CPU 
Mul: GPU CPU 
AssignVariableOp: GPU CPU 
StatelessRandomGetKeyCounter: CPU 
AddV2: GPU CPU 
VarIsInitializedOp: GPU CPU 
StatelessTruncatedNormalV2: GPU CPU 
Const: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  Embedding-Segment/embeddings/Initializer/stateless_truncated_normal/shape (Const) 
  Embedding-Segment/embeddings/Initializer/stateless_truncated_normal/mean (Const) 
  Embedding-Segment/embeddings/Initializer/stateless_truncated_normal/stddev (Const) 
  Embedding-Segment/embeddings/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter/seed (Const) 
  Embedding-Segment/embeddings/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter (StatelessRandomGetKeyCounter) 
  Embedding-Segment/embeddings/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2/alg (Const) 
  Embedding-Segment/embeddings/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2 (StatelessTruncatedNormalV2) 
  Embedding-Segment/embeddings/Initializer/stateless_truncated_normal/mul (Mul) 
  Embedding-Segment/embeddings/Initializer/stateless_truncated_normal (AddV2) 
  Embedding-Segment/embeddings (VarHandleOp) /replica:0/task:0/device:GPU:0
  Embedding-Segment/embeddings/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /replica:0/task:0/device:GPU:0
  Embedding-Segment/embeddings/Assign (AssignVariableOp) /replica:0/task:0/device:GPU:0
  Embedding-Segment/embeddings/Read/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  Embedding-Segment/embedding_lookup/Identity/ReadVariableOp (ReadVariableOp) 
  Identity_1/ReadVariableOp (ReadVariableOp) 
  update_0_1/AssignVariableOp (AssignVariableOp) /replica:0/task:0/device:GPU:0
  update_0_1/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  VarIsInitializedOp_12 (VarIsInitializedOp) 
  VarIsInitializedOp_13 (VarIsInitializedOp) 

2026-02-04 00:58:04.631878: W tensorflow/core/common_runtime/colocation_graph.cc:1213] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ReadVariableOp: GPU CPU 
VarHandleOp: GPU CPU 
Mul: GPU CPU 
AssignVariableOp: GPU CPU 
StatelessRandomGetKeyCounter: CPU 
AddV2: GPU CPU 
VarIsInitializedOp: GPU CPU 
StatelessTruncatedNormalV2: GPU CPU 
Const: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  Embedding-Position/embeddings/Initializer/stateless_truncated_normal/shape (Const) 
  Embedding-Position/embeddings/Initializer/stateless_truncated_normal/mean (Const) 
  Embedding-Position/embeddings/Initializer/stateless_truncated_normal/stddev (Const) 
  Embedding-Position/embeddings/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter/seed (Const) 
  Embedding-Position/embeddings/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter (StatelessRandomGetKeyCounter) 
  Embedding-Position/embeddings/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2/alg (Const) 
  Embedding-Position/embeddings/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2 (StatelessTruncatedNormalV2) 
  Embedding-Position/embeddings/Initializer/stateless_truncated_normal/mul (Mul) 
  Embedding-Position/embeddings/Initializer/stateless_truncated_normal (AddV2) 
  Embedding-Position/embeddings (VarHandleOp) /replica:0/task:0/device:GPU:0
  Embedding-Position/embeddings/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /replica:0/task:0/device:GPU:0
  Embedding-Position/embeddings/Assign (AssignVariableOp) /replica:0/task:0/device:GPU:0
  Embedding-Position/embeddings/Read/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  Embedding-Position/Identity/ReadVariableOp (ReadVariableOp) 
  Identity_2/ReadVariableOp (ReadVariableOp) 
  update_0_2/AssignVariableOp (AssignVariableOp) /replica:0/task:0/device:GPU:0
  update_0_2/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  VarIsInitializedOp_40 (VarIsInitializedOp) 
  VarIsInitializedOp_41 (VarIsInitializedOp) 

2026-02-04 00:58:04.631908: W tensorflow/core/common_runtime/colocation_graph.cc:1213] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ReadVariableOp: GPU CPU 
VarHandleOp: GPU CPU 
Mul: GPU CPU 
AssignVariableOp: GPU CPU 
StatelessRandomGetKeyCounter: CPU 
AddV2: GPU CPU 
VarIsInitializedOp: GPU CPU 
StatelessTruncatedNormalV2: GPU CPU 
Const: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  Embedding-Mapping/kernel/Initializer/stateless_truncated_normal/shape (Const) 
  Embedding-Mapping/kernel/Initializer/stateless_truncated_normal/mean (Const) 
  Embedding-Mapping/kernel/Initializer/stateless_truncated_normal/stddev (Const) 
  Embedding-Mapping/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter/seed (Const) 
  Embedding-Mapping/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter (StatelessRandomGetKeyCounter) 
  Embedding-Mapping/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2/alg (Const) 
  Embedding-Mapping/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2 (StatelessTruncatedNormalV2) 
  Embedding-Mapping/kernel/Initializer/stateless_truncated_normal/mul (Mul) 
  Embedding-Mapping/kernel/Initializer/stateless_truncated_normal (AddV2) 
  Embedding-Mapping/kernel (VarHandleOp) /replica:0/task:0/device:GPU:0
  Embedding-Mapping/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /replica:0/task:0/device:GPU:0
  Embedding-Mapping/kernel/Assign (AssignVariableOp) /replica:0/task:0/device:GPU:0
  Embedding-Mapping/kernel/Read/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  Embedding-Mapping/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  Identity_5/ReadVariableOp (ReadVariableOp) 
  update_0_5/AssignVariableOp (AssignVariableOp) /replica:0/task:0/device:GPU:0
  update_0_5/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  VarIsInitializedOp_2 (VarIsInitializedOp) 
  VarIsInitializedOp_3 (VarIsInitializedOp) 

2026-02-04 00:58:04.631934: W tensorflow/core/common_runtime/colocation_graph.cc:1213] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ReadVariableOp: GPU CPU 
VarHandleOp: GPU CPU 
Mul: GPU CPU 
AssignVariableOp: GPU CPU 
StatelessRandomGetKeyCounter: CPU 
AddV2: GPU CPU 
VarIsInitializedOp: GPU CPU 
StatelessTruncatedNormalV2: GPU CPU 
Const: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  Transformer-MultiHeadSelfAttention/dense/kernel/Initializer/stateless_truncated_normal/shape (Const) 
  Transformer-MultiHeadSelfAttention/dense/kernel/Initializer/stateless_truncated_normal/mean (Const) 
  Transformer-MultiHeadSelfAttention/dense/kernel/Initializer/stateless_truncated_normal/stddev (Const) 
  Transformer-MultiHeadSelfAttention/dense/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter/seed (Const) 
  Transformer-MultiHeadSelfAttention/dense/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter (StatelessRandomGetKeyCounter) 
  Transformer-MultiHeadSelfAttention/dense/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2/alg (Const) 
  Transformer-MultiHeadSelfAttention/dense/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2 (StatelessTruncatedNormalV2) 
  Transformer-MultiHeadSelfAttention/dense/kernel/Initializer/stateless_truncated_normal/mul (Mul) 
  Transformer-MultiHeadSelfAttention/dense/kernel/Initializer/stateless_truncated_normal (AddV2) 
  Transformer-MultiHeadSelfAttention/dense/kernel (VarHandleOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense/kernel/Assign (AssignVariableOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense/kernel/Read/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  Transformer-MultiHeadSelfAttention_1/dense/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  VarIsInitializedOp_18 (VarIsInitializedOp) 
  VarIsInitializedOp_19 (VarIsInitializedOp) 

2026-02-04 00:58:04.631956: W tensorflow/core/common_runtime/colocation_graph.cc:1213] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ReadVariableOp: GPU CPU 
VarHandleOp: GPU CPU 
Mul: GPU CPU 
AssignVariableOp: GPU CPU 
StatelessRandomGetKeyCounter: CPU 
AddV2: GPU CPU 
VarIsInitializedOp: GPU CPU 
StatelessTruncatedNormalV2: GPU CPU 
Const: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  Transformer-MultiHeadSelfAttention/dense_1/kernel/Initializer/stateless_truncated_normal/shape (Const) 
  Transformer-MultiHeadSelfAttention/dense_1/kernel/Initializer/stateless_truncated_normal/mean (Const) 
  Transformer-MultiHeadSelfAttention/dense_1/kernel/Initializer/stateless_truncated_normal/stddev (Const) 
  Transformer-MultiHeadSelfAttention/dense_1/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter/seed (Const) 
  Transformer-MultiHeadSelfAttention/dense_1/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter (StatelessRandomGetKeyCounter) 
  Transformer-MultiHeadSelfAttention/dense_1/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2/alg (Const) 
  Transformer-MultiHeadSelfAttention/dense_1/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2 (StatelessTruncatedNormalV2) 
  Transformer-MultiHeadSelfAttention/dense_1/kernel/Initializer/stateless_truncated_normal/mul (Mul) 
  Transformer-MultiHeadSelfAttention/dense_1/kernel/Initializer/stateless_truncated_normal (AddV2) 
  Transformer-MultiHeadSelfAttention/dense_1/kernel (VarHandleOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense_1/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense_1/kernel/Assign (AssignVariableOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense_1/kernel/Read/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense_1/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  Transformer-MultiHeadSelfAttention_1/dense_1/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  VarIsInitializedOp_14 (VarIsInitializedOp) 
  VarIsInitializedOp_15 (VarIsInitializedOp) 

2026-02-04 00:58:04.631980: W tensorflow/core/common_runtime/colocation_graph.cc:1213] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ReadVariableOp: GPU CPU 
VarHandleOp: GPU CPU 
Mul: GPU CPU 
AssignVariableOp: GPU CPU 
StatelessRandomGetKeyCounter: CPU 
AddV2: GPU CPU 
VarIsInitializedOp: GPU CPU 
StatelessTruncatedNormalV2: GPU CPU 
Const: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  Transformer-MultiHeadSelfAttention/dense_2/kernel/Initializer/stateless_truncated_normal/shape (Const) 
  Transformer-MultiHeadSelfAttention/dense_2/kernel/Initializer/stateless_truncated_normal/mean (Const) 
  Transformer-MultiHeadSelfAttention/dense_2/kernel/Initializer/stateless_truncated_normal/stddev (Const) 
  Transformer-MultiHeadSelfAttention/dense_2/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter/seed (Const) 
  Transformer-MultiHeadSelfAttention/dense_2/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter (StatelessRandomGetKeyCounter) 
  Transformer-MultiHeadSelfAttention/dense_2/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2/alg (Const) 
  Transformer-MultiHeadSelfAttention/dense_2/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2 (StatelessTruncatedNormalV2) 
  Transformer-MultiHeadSelfAttention/dense_2/kernel/Initializer/stateless_truncated_normal/mul (Mul) 
  Transformer-MultiHeadSelfAttention/dense_2/kernel/Initializer/stateless_truncated_normal (AddV2) 
  Transformer-MultiHeadSelfAttention/dense_2/kernel (VarHandleOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense_2/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense_2/kernel/Assign (AssignVariableOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense_2/kernel/Read/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense_2/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  Transformer-MultiHeadSelfAttention_1/dense_2/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  VarIsInitializedOp_50 (VarIsInitializedOp) 
  VarIsInitializedOp_51 (VarIsInitializedOp) 

2026-02-04 00:58:04.632009: W tensorflow/core/common_runtime/colocation_graph.cc:1213] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ReadVariableOp: GPU CPU 
VarHandleOp: GPU CPU 
Mul: GPU CPU 
AssignVariableOp: GPU CPU 
StatelessRandomGetKeyCounter: CPU 
AddV2: GPU CPU 
VarIsInitializedOp: GPU CPU 
StatelessTruncatedNormalV2: GPU CPU 
Const: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  Transformer-MultiHeadSelfAttention/dense_3/kernel/Initializer/stateless_truncated_normal/shape (Const) 
  Transformer-MultiHeadSelfAttention/dense_3/kernel/Initializer/stateless_truncated_normal/mean (Const) 
  Transformer-MultiHeadSelfAttention/dense_3/kernel/Initializer/stateless_truncated_normal/stddev (Const) 
  Transformer-MultiHeadSelfAttention/dense_3/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter/seed (Const) 
  Transformer-MultiHeadSelfAttention/dense_3/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter (StatelessRandomGetKeyCounter) 
  Transformer-MultiHeadSelfAttention/dense_3/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2/alg (Const) 
  Transformer-MultiHeadSelfAttention/dense_3/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2 (StatelessTruncatedNormalV2) 
  Transformer-MultiHeadSelfAttention/dense_3/kernel/Initializer/stateless_truncated_normal/mul (Mul) 
  Transformer-MultiHeadSelfAttention/dense_3/kernel/Initializer/stateless_truncated_normal (AddV2) 
  Transformer-MultiHeadSelfAttention/dense_3/kernel (VarHandleOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense_3/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense_3/kernel/Assign (AssignVariableOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense_3/kernel/Read/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  Transformer-MultiHeadSelfAttention/dense_3/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  Transformer-MultiHeadSelfAttention_1/dense_3/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  VarIsInitializedOp_22 (VarIsInitializedOp) 
  VarIsInitializedOp_23 (VarIsInitializedOp) 

2026-02-04 00:58:04.632036: W tensorflow/core/common_runtime/colocation_graph.cc:1213] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ReadVariableOp: GPU CPU 
VarHandleOp: GPU CPU 
Mul: GPU CPU 
AssignVariableOp: GPU CPU 
StatelessRandomGetKeyCounter: CPU 
AddV2: GPU CPU 
VarIsInitializedOp: GPU CPU 
StatelessTruncatedNormalV2: GPU CPU 
Const: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  Transformer-FeedForward/dense_4/kernel/Initializer/stateless_truncated_normal/shape (Const) 
  Transformer-FeedForward/dense_4/kernel/Initializer/stateless_truncated_normal/mean (Const) 
  Transformer-FeedForward/dense_4/kernel/Initializer/stateless_truncated_normal/stddev (Const) 
  Transformer-FeedForward/dense_4/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter/seed (Const) 
  Transformer-FeedForward/dense_4/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter (StatelessRandomGetKeyCounter) 
  Transformer-FeedForward/dense_4/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2/alg (Const) 
  Transformer-FeedForward/dense_4/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2 (StatelessTruncatedNormalV2) 
  Transformer-FeedForward/dense_4/kernel/Initializer/stateless_truncated_normal/mul (Mul) 
  Transformer-FeedForward/dense_4/kernel/Initializer/stateless_truncated_normal (AddV2) 
  Transformer-FeedForward/dense_4/kernel (VarHandleOp) /replica:0/task:0/device:GPU:0
  Transformer-FeedForward/dense_4/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /replica:0/task:0/device:GPU:0
  Transformer-FeedForward/dense_4/kernel/Assign (AssignVariableOp) /replica:0/task:0/device:GPU:0
  Transformer-FeedForward/dense_4/kernel/Read/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  Transformer-FeedForward/dense_4/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  Transformer-FeedForward_1/dense_4/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  VarIsInitializedOp_4 (VarIsInitializedOp) 
  VarIsInitializedOp_5 (VarIsInitializedOp) 

2026-02-04 00:58:04.632061: W tensorflow/core/common_runtime/colocation_graph.cc:1213] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ReadVariableOp: GPU CPU 
VarHandleOp: GPU CPU 
Mul: GPU CPU 
AssignVariableOp: GPU CPU 
StatelessRandomGetKeyCounter: CPU 
AddV2: GPU CPU 
VarIsInitializedOp: GPU CPU 
StatelessTruncatedNormalV2: GPU CPU 
Const: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  Transformer-FeedForward/dense_5/kernel/Initializer/stateless_truncated_normal/shape (Const) 
  Transformer-FeedForward/dense_5/kernel/Initializer/stateless_truncated_normal/mean (Const) 
  Transformer-FeedForward/dense_5/kernel/Initializer/stateless_truncated_normal/stddev (Const) 
  Transformer-FeedForward/dense_5/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter/seed (Const) 
  Transformer-FeedForward/dense_5/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter (StatelessRandomGetKeyCounter) 
  Transformer-FeedForward/dense_5/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2/alg (Const) 
  Transformer-FeedForward/dense_5/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2 (StatelessTruncatedNormalV2) 
  Transformer-FeedForward/dense_5/kernel/Initializer/stateless_truncated_normal/mul (Mul) 
  Transformer-FeedForward/dense_5/kernel/Initializer/stateless_truncated_normal (AddV2) 
  Transformer-FeedForward/dense_5/kernel (VarHandleOp) /replica:0/task:0/device:GPU:0
  Transformer-FeedForward/dense_5/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /replica:0/task:0/device:GPU:0
  Transformer-FeedForward/dense_5/kernel/Assign (AssignVariableOp) /replica:0/task:0/device:GPU:0
  Transformer-FeedForward/dense_5/kernel/Read/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  Transformer-FeedForward/dense_5/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  Transformer-FeedForward_1/dense_5/Tensordot/Identity/ReadVariableOp (ReadVariableOp) 
  VarIsInitializedOp_38 (VarIsInitializedOp) 
  VarIsInitializedOp_39 (VarIsInitializedOp) 

2026-02-04 00:58:04.632122: W tensorflow/core/common_runtime/colocation_graph.cc:1213] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [
  /job:localhost/replica:0/task:0/device:CPU:0].
See below for details of this colocation group:
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=-1 requested_device_name_='/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
ReadVariableOp: GPU CPU 
VarHandleOp: GPU CPU 
Mul: GPU CPU 
AssignVariableOp: GPU CPU 
StatelessRandomGetKeyCounter: CPU 
AddV2: GPU CPU 
VarIsInitializedOp: GPU CPU 
StatelessTruncatedNormalV2: GPU CPU 
Const: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  CLS-Activation/kernel/Initializer/stateless_truncated_normal/shape (Const) 
  CLS-Activation/kernel/Initializer/stateless_truncated_normal/mean (Const) 
  CLS-Activation/kernel/Initializer/stateless_truncated_normal/stddev (Const) 
  CLS-Activation/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter/seed (Const) 
  CLS-Activation/kernel/Initializer/stateless_truncated_normal/StatelessRandomGetKeyCounter (StatelessRandomGetKeyCounter) 
  CLS-Activation/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2/alg (Const) 
  CLS-Activation/kernel/Initializer/stateless_truncated_normal/StatelessTruncatedNormalV2 (StatelessTruncatedNormalV2) 
  CLS-Activation/kernel/Initializer/stateless_truncated_normal/mul (Mul) 
  CLS-Activation/kernel/Initializer/stateless_truncated_normal (AddV2) 
  CLS-Activation/kernel (VarHandleOp) /replica:0/task:0/device:GPU:0
  CLS-Activation/kernel/IsInitialized/VarIsInitializedOp (VarIsInitializedOp) /replica:0/task:0/device:GPU:0
  CLS-Activation/kernel/Assign (AssignVariableOp) /replica:0/task:0/device:GPU:0
  CLS-Activation/kernel/Read/ReadVariableOp (ReadVariableOp) /replica:0/task:0/device:GPU:0
  CLS-Activation/MatMul/Identity/ReadVariableOp (ReadVariableOp) 
  VarIsInitializedOp_46 (VarIsInitializedOp) 
  VarIsInitializedOp_47 (VarIsInitializedOp) 

2026-02-04 00:58:04.641327: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:04.789840: W tensorflow/c/c_api.cc:304] Operation '{name:'CLS-Activation/bias/Assign' id:871 op device:{requested: '/replica:0/task:0/device:GPU:0', assigned: ''} def:{{{node CLS-Activation/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false, _device="/replica:0/task:0/device:GPU:0"](CLS-Activation/bias, CLS-Activation/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2026-02-04 00:58:04.796900: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:04.849284: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
Load weights:  99_PreTrain_Model_Weight/LOGO_5_gram_2_layer_8_heads_256_dim_weights_32-0.885107.hdf5
GLOBAL_BATCH_SIZE:  2
shuffle_size:  1000
actg_value [1 2 3 4]
n_gram_value:  [1.e+04 1.e+03 1.e+02 1.e+01 1.e+00]
VCF file shape is : 
 (19, 5)
shift is  0
__Fetching Seqs...__
catch refseq length: 356
catch altseq length: 356
Number of variants with reference allele matched with reference genome:
2
Number of input variants:
19
Computing 1st file..
__Processing REF Seqs and ALT Seqs__
seqslist length : 10, 
tem_encoded shape : (20, 4, 256)
20
seqslist length : 9, 
tem_encoded shape : (18, 4, 256)
18
seqslist length : 10, 
tem_encoded shape : (20, 4, 256)
20
seqslist length : 9, 
tem_encoded shape : (18, 4, 256)
18
WARNING:tensorflow:From 04_LOGO_Chromatin_Feature/1. script/04_LOGO_Chrom_predict/GeneBert_predict_vcf_slice_e8.py:526: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.
Instructions for updating:
Use output_signature instead
WARNING:tensorflow:From 04_LOGO_Chromatin_Feature/1. script/04_LOGO_Chrom_predict/GeneBert_predict_vcf_slice_e8.py:526: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.
Instructions for updating:
Use output_signature instead
/opt/anaconda3/envs/logo-lite/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:468: UserWarning: To make it possible to preserve tf.data options across serialization boundaries, their implementation has moved to be part of the TensorFlow graph. As a consequence, the options value is in general no longer known at graph construction time. Invoking this method in graph mode retains the legacy behavior of the original implementation, but note that the returned value might not reflect the actual value of the options.
  warnings.warn("To make it possible to preserve tf.data options across "
WARNING:tensorflow:From /opt/anaconda3/envs/logo-lite/lib/python3.8/site-packages/tensorflow/python/distribute/v1/input_lib.py:198: DistributedIteratorV1.initialize (from tensorflow.python.distribute.v1.input_lib) is deprecated and will be removed in a future version.
Instructions for updating:
Use the iterator's `initializer` property instead.
2026-02-04 00:58:07.169741: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.179679: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.181333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.182954: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.183981: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.184956: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.185345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.195776: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\017TensorDataset:0"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

2026-02-04 00:58:07.206882: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.207820: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.208958: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.209896: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
/opt/anaconda3/envs/logo-lite/lib/python3.8/contextlib.py:113: UserWarning: `tf.keras.backend.learning_phase_scope` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  return next(self.gen)
WARNING:tensorflow:From /opt/anaconda3/envs/logo-lite/lib/python3.8/site-packages/keras/src/distribute/distributed_training_utils_v1.py:364: StrategyBase.unwrap (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
use `experimental_local_results` instead.
2026-02-04 00:58:07.296579: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.308717: W tensorflow/c/c_api.cc:304] Operation '{name:'total_1/Assign' id:1772 op device:{requested: '/replica:0/task:0/device:GPU:0', assigned: ''} def:{{{node total_1/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false, _device="/replica:0/task:0/device:GPU:0"](total_1, total_1/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2026-02-04 00:58:07.319995: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.325985: W tensorflow/c/c_api.cc:304] Operation '{name:'predict/group_deps' id:1831 op device:{requested: '/replica:0/task:0/device:GPU:0', assigned: ''} def:{{{node predict/group_deps}} = NoOp[_has_manual_control_dependencies=true, _device="/replica:0/task:0/device:GPU:0"](^CLS-Activation_1/Sigmoid)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2026-02-04 00:58:07.337434: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.950636: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.959622: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.960682: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.961063: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.961159: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.962196: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.964346: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.971669: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\020TensorDataset:12"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

2026-02-04 00:58:07.980670: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.981671: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.982943: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:07.983776: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.018798: W tensorflow/c/c_api.cc:304] Operation '{name:'predict/group_deps' id:1831 op device:{requested: '/replica:0/task:0/device:GPU:0', assigned: ''} def:{{{node predict/group_deps}} = NoOp[_has_manual_control_dependencies=true, _device="/replica:0/task:0/device:GPU:0"](^CLS-Activation_1/Sigmoid)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2026-02-04 00:58:08.032531: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.613541: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.622633: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.623134: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.624402: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.624506: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.625529: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.626525: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.634595: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\020TensorDataset:24"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

2026-02-04 00:58:08.643271: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.644186: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.645427: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.646629: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:08.679918: W tensorflow/c/c_api.cc:304] Operation '{name:'predict/group_deps' id:1831 op device:{requested: '/replica:0/task:0/device:GPU:0', assigned: ''} def:{{{node predict/group_deps}} = NoOp[_has_manual_control_dependencies=true, _device="/replica:0/task:0/device:GPU:0"](^CLS-Activation_1/Sigmoid)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2026-02-04 00:58:08.694551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.266353: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.277177: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.277331: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.278771: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.280235: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.280727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.281826: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.289907: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\020TensorDataset:36"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

2026-02-04 00:58:09.298905: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.299876: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.301176: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.302023: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.334148: W tensorflow/c/c_api.cc:304] Operation '{name:'predict/group_deps' id:1831 op device:{requested: '/replica:0/task:0/device:GPU:0', assigned: ''} def:{{{node predict/group_deps}} = NoOp[_has_manual_control_dependencies=true, _device="/replica:0/task:0/device:GPU:0"](^CLS-Activation_1/Sigmoid)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2026-02-04 00:58:09.350393: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.922517: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.933979: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.935312: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.936331: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.936706: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.936838: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.938355: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.945653: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\020TensorDataset:48"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

2026-02-04 00:58:09.954502: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.955427: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.956662: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.957533: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:09.990379: W tensorflow/c/c_api.cc:304] Operation '{name:'predict/group_deps' id:1831 op device:{requested: '/replica:0/task:0/device:GPU:0', assigned: ''} def:{{{node predict/group_deps}} = NoOp[_has_manual_control_dependencies=true, _device="/replica:0/task:0/device:GPU:0"](^CLS-Activation_1/Sigmoid)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2026-02-04 00:58:10.006928: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:10.599194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:10.611594: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:10.612076: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:10.613644: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:10.614763: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:10.616401: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:10.617685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:10.624863: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\020TensorDataset:60"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

2026-02-04 00:58:10.634192: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:10.635168: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:10.636416: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:10.637295: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:10.668651: W tensorflow/c/c_api.cc:304] Operation '{name:'predict/group_deps' id:1831 op device:{requested: '/replica:0/task:0/device:GPU:0', assigned: ''} def:{{{node predict/group_deps}} = NoOp[_has_manual_control_dependencies=true, _device="/replica:0/task:0/device:GPU:0"](^CLS-Activation_1/Sigmoid)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2026-02-04 00:58:10.686869: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.267761: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.281367: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.281503: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.282629: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.283099: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.284416: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.285479: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.293886: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\020TensorDataset:72"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

2026-02-04 00:58:11.302966: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.303911: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.305200: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.306117: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.340122: W tensorflow/c/c_api.cc:304] Operation '{name:'predict/group_deps' id:1831 op device:{requested: '/replica:0/task:0/device:GPU:0', assigned: ''} def:{{{node predict/group_deps}} = NoOp[_has_manual_control_dependencies=true, _device="/replica:0/task:0/device:GPU:0"](^CLS-Activation_1/Sigmoid)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2026-02-04 00:58:11.359625: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.959179: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.973564: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.974080: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.975245: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.976632: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.977745: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.979701: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.986651: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\020TensorDataset:84"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

2026-02-04 00:58:11.995543: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.996874: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.998295: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:11.999217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.031881: W tensorflow/c/c_api.cc:304] Operation '{name:'predict/group_deps' id:1831 op device:{requested: '/replica:0/task:0/device:GPU:0', assigned: ''} def:{{{node predict/group_deps}} = NoOp[_has_manual_control_dependencies=true, _device="/replica:0/task:0/device:GPU:0"](^CLS-Activation_1/Sigmoid)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2026-02-04 00:58:12.051925: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.656752: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.671793: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.672986: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.673152: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.674956: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.676000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.676488: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.684771: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\020TensorDataset:96"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

2026-02-04 00:58:12.694025: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.694995: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.696590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.697559: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:12.730774: W tensorflow/c/c_api.cc:304] Operation '{name:'predict/group_deps' id:1831 op device:{requested: '/replica:0/task:0/device:GPU:0', assigned: ''} def:{{{node predict/group_deps}} = NoOp[_has_manual_control_dependencies=true, _device="/replica:0/task:0/device:GPU:0"](^CLS-Activation_1/Sigmoid)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2026-02-04 00:58:12.752014: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:13.364392: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:13.380007: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:13.381170: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:13.382268: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:13.384092: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:13.385472: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:13.385562: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:13.392928: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: "TensorDataset/_1"
op: "TensorDataset"
input: "Placeholder/_0"
attr {
  key: "Toutput_types"
  value {
    list {
      type: DT_INT32
    }
  }
}
attr {
  key: "_cardinality"
  value {
    i: 1
  }
}
attr {
  key: "metadata"
  value {
    s: "\n\021TensorDataset:108"
  }
}
attr {
  key: "output_shapes"
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_INT32
        }
      }
    }
  }
}

2026-02-04 00:58:13.402314: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:13.403256: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:13.404481: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:13.405319: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
2026-02-04 00:58:13.437714: W tensorflow/c/c_api.cc:304] Operation '{name:'predict/group_deps' id:1831 op device:{requested: '/replica:0/task:0/device:GPU:0', assigned: ''} def:{{{node predict/group_deps}} = NoOp[_has_manual_control_dependencies=true, _device="/replica:0/task:0/device:GPU:0"](^CLS-Activation_1/Sigmoid)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.
2026-02-04 00:58:13.460475: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
/opt/anaconda3/envs/logo-lite/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 6 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
